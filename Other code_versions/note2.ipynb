{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77822c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydicom numpy pillow torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a7fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickTestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.pet = [np.random.rand(256,256) for _ in range(5)]\n",
    "        self.ct = [np.random.rand(256,256) for _ in range(5)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 5\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.pet[idx][None]), torch.tensor(self.ct[idx][None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddb2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 1, 4, stride=2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368188f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "G = MiniGenerator().to(device)\n",
    "opt = torch.optim.Adam(G.parameters(), lr=1e-4)\n",
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Fast Training Loop\n",
    "# ==============================\n",
    "def quick_train():\n",
    "    dataset = QuickTestDataset()\n",
    "    loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "    \n",
    "    for epoch in range(3):  # 3 epochs only\n",
    "        for pet, ct in loader:\n",
    "            pet, ct = pet.float().to(device), ct.float().to(device)\n",
    "            opt.zero_grad()\n",
    "            fake_ct = G(pet)\n",
    "            loss = criterion(fake_ct, ct)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31846b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Run & Verify\n",
    "# ==============================\n",
    "if __name__ == \"__main__\":\n",
    "    quick_train()\n",
    "    print(\"\\nâœ… Quick test successful! Now run full notebook.\")\n",
    "    \n",
    "    # Sample output visualization\n",
    "    test_input = torch.randn(1, 1, 256, 256).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = G(test_input).cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(121).imshow(test_input[0,0].cpu(), cmap='gray')\n",
    "    plt.title('Input PET')\n",
    "    plt.subplot(122).imshow(output[0,0], cmap='gray')\n",
    "    plt.title('Generated CT')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
